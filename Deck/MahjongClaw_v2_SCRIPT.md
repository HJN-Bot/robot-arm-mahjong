# 麻将爪 MahjongClaw · PPT 内容文稿 v2

> 用途：按此文稿修改 `MahjongClaw_v2.pptx` 的每页文案与逻辑；含**可照读的口语化稿件**、页间串联、配图建议。
> 对齐文档：`docs/PITCH_DECK.md`、`docs/SIGNAL_FLOW.md`、`docs/OPENCLAW_SYSTEM_PROMPT.md`

---

## 一、整体叙事框架（从「OpenClaw 时刻」到「硬件 3.0」）

### 核心问题（贯穿全稿）
**当你的专属 AI 有了物理世界的意义，会发生什么？**  
我们用 48 小时和一台机械臂来预言「硬件 3.0」：不再只是对话，而是**在场**——能抓、能看、能扔、能开口。

### 三幕结构
| 幕 | 作用 | 对应页 |
|----|------|--------|
| **Why** | OpenClaw 已经懂你，但还困在屏幕里；我们要给它身体 | 问题页 |
| **What** | Body（机械臂）+ Brain（OpenClaw）合体，一句指令触发物理动作 | 双线页、执行链路页、体验页 |
| **How / So What** | 模块化、可 Fork；商业与路线图收束到技术平权 | 架构页、商业页、市场与路线图页 |

---

## 二、开场 + 每页稿件（可照读 / 稍作发挥）

---

### 开场（封面出现前或 P1 时讲）

OpenClaw 的 moment 深刻诠释了一件事：**当模型有了专属于你的记忆，会发生什么？** 一月底，全世界的 AI 爱好者大概都激动了——OpenClaw 开源项目成了 GitHub 历史上标星涨得最快的项目之一。我也是那百万 star 里的一员。当我深度用上这份定制、专属、私人的 AI 之后，和很多人一样，我在想：**它能不能做得更多？** 所以我们用 48 小时做了一次小实验，与其说是 Demo，不如说是对**硬件 3.0** 的一次预言。我们要回答的就是：**当你的专属 AI 有了物理世界的意义，会发生什么？** 今天这张片子，就是我们的答案。

---

### 第 1 页｜封面

**标题（主）**  
麻将爪 MahjongClaw  

**副标题**  
Soma Robotics × OpenClaw  

**一句话（主视觉旁白）**  
给 AI 一具身体，让机器人真正「在场」。

**P1 稿件内容**  
答案有一个名字，叫「麻将爪」——MahjongClaw。背后是 Soma 的机械臂和 OpenClaw 的大脑。一句话概括：**给 AI 一具身体，让机器人真正在场。** 接下来几页我会说清楚：我们遇到了什么问题、怎么拆成身体和大脑、从你发一条消息到机械臂动起来究竟经过哪几步，以及这件事为什么值得持续做下去。

**配图/设计建议**  
- 主视觉：机械臂 + 麻将牌 + Discord/屏幕的合成图，或 Demo 静帧（抓牌/看牌/扔牌之一）。
- LOGO：Soma + OpenClaw 并排；深色底 + 高对比标题。

**本页小结**  
麻将爪 = 机械臂（Body）+ OpenClaw（Brain），把「对话」变成「动作」，让 AI 从屏幕里走到现实里。（注：若屏显曾误作「麦将爪」，请统一为「麻将爪」。）

---

### 第 2 页｜钩子 / 金句

**正文（屏显）**  
Agent 走出了屏幕。  
它抓牌。它开口。  
它在场。

**P2 稿件内容**  
用三句话收束一下：**Agent 走出了屏幕。它抓牌。它开口。它在场。** 不再是你问它答、它只能待在对话框里——而是你一说「来一局」，它就真的伸手、抓牌、凑到摄像头前「看」一眼、然后扔出去或收回来，再配上一句带人格的解说。这就是我们说的「在场」：可触达、可听见、可看见。

**配图/设计建议**  
- 三行字配三张小图：屏幕/对话框 → 机械臂抓牌 → 人与臂同框或 TTS 声波；或纯文字 + 留白，突出「在场」。

**本页小结**  
从「只能聊」到「能动手、能出声、能在场」。

---

### 第 3 页｜问题（Why）

**标题**  
AI 很聪明——但被困在屏幕后面  

**三条痛点（屏显，每条配小图标）**  

| 痛点 | 短句 | 展开（备注/副文案） |
|------|------|---------------------------|
| 能说，不能动 | 困在屏幕里 | AI 能给出绝妙的麻将策略，却无法翻一张牌、移动一枚棋子，或用任何物理方式表达「我在场」。 |
| 触达不到 | 所有交互停留在数字世界 | 你的牌桌、你的游戏、你的空间——AI 完全触达不到。 |
| 太难上手 | 极客玩具永远只是玩具 | 让机器人响应自然语言，往往需要深厚的机器人专业知识；我们想降低这道门槛。 |

**P3 稿件内容**  
但现实是，今天绝大多数 AI 还做不到「在场」。**AI 很聪明，却被困在屏幕后面。** 第一，它能说不能动——能给你绝妙的麻将策略，却没法真的翻一张牌、挪一枚棋子；第二，所有交互都停在数字世界，你的牌桌、你的空间，它触达不到；第三，让机器人听懂人话并动起来，传统上要搞串口、运动学、一大堆协议，极客玩具永远只是极客的玩具。OpenClaw 已经证明了「专属记忆」的价值；我们想再往前一步：**当这份大脑接上一具身体，会怎样？** 这就是我们要解决的问题。

**配图/设计建议**  
- 左：对话框/屏幕里的 AI；右：真实牌桌/机械臂；用「屏幕边界」或箭头表示「突破」。或三列：每列一个痛点 + 一句金句 + icon。

**本页小结**  
问题 = AI 缺身体、缺触达、缺可及性；我们要做的是「可触达、可共创、可日常化」的陪伴。

---

### 第 4 页｜What：身体 + 大脑

**标题**  
身体 + 大脑 = 真正懂你的机器人  

**左列 · 身体｜机械臂**  
- 精准抓取、持握、放置麻将牌；看牌动作——回收、停顿，像在思考。  
- 将弃牌扔至牌桌正中央；点头 / 摇头 / 三连点，完整肢体语言。  
- Python + LeRobot，完全离线运行，即插即用。  

**右列 · 大脑｜OpenClaw AI**  
- 理解自然语言指令，记住你的风格、语气与偏好。  
- 地域/陪玩角色/难度可自然语言配置（如「来一局四川麻将找个赌神」）；人格：礼貌版 ⇔ 梗版。  
- Discord 一句指令 → 机械臂动作，响应 &lt; 1 秒。  

**P4 稿件内容**  
我们的答案很简单：**身体交给机械臂，大脑交给 OpenClaw。** 左边是身体——能抓、能看、能扔、能点头摇头点三点，用 Python 和 LeRobot 在本地跑，即插即用；右边是大脑，就是你熟悉的那个「有记忆」的 OpenClaw，只不过这次它不只回你一句话，而是真的去调 Mac 上的 Orchestrator、让机械臂动起来。你可以在 Discord 里说「来一局四川麻将找个赌神」，它从自然语言里抽出地域、陪玩角色、难度，再触发动作。**身体 + 大脑，缺一不可**——没有身体，大脑只能聊；没有大脑，机械臂只是遥控玩具。合体之后，才是「真正懂你的机器人」。

**配图/设计建议**  
- 左右分栏：左机械臂/手部特写，右 OpenClaw/Discord 或 Brain 示意图；中间「+」或「合体」符号。

**本页小结**  
机械臂 = 可触达的执行器（Body）；OpenClaw = 有灵魂的决策与记忆（Brain）；合体后从对话到动作。

---

### 第 5 页｜How：一条消息到物理动作

**标题**  
一条消息，立即触发物理动作  

**5 步执行链路（与真实信号链一致）**  
1. 💬 **Discord** 输入指令（如「来一局」「来一局四川麻将找个赌神」）  
2. → 🧠 **OpenClaw（EC2）** 解析意图，提取地域/陪玩角色/难度，调用 Mac Hub：`POST /activate` 唤醒摄像头与轮询，`POST /trigger` 触发一次开牌  
3. → 📡 **Tailscale** 加密路由（EC2 ↔ Mac），HTTP 直达，零配置  
4. → ⚙️ **Mac Hub · Orchestrator** 浏览器 800ms 轮询到 `trigger_pending=true`，执行 autoLoopTick：`/arm/start_scene` → 机械臂 pick_tile、present_to_camera → 截帧 4 次送视觉识别（白板/一筒）→ `/execute_scene` 决定 Scene A 扔出 或 Scene B 退回  
5. → 🦾 **机械臂** 执行 throw_to_discard 或 return_tile，本地 TTS 播报，前端播放对应动画；OpenClaw 轮询到 `recognized` 后生成带人格的解说回 Discord  

**Demo 一句话**  
用户说「来一局四川麻将找个赌神」→ 臂抓牌 → 凑到摄像头前「看」→ 识别白板则扔出、一筒则退回，并配赌神口吻解说；单次约 3–8 秒，连续 10 次成功率 ≥ 80%。

**P5 稿件内容**  
从你发出一条消息到机械臂动起来，整条链路是这样的。你在 Discord 说一句「来一局」或「来一局四川麻将找个赌神」，OpenClaw 在 EC2 上解析出地域、陪玩角色、难度，通过 Tailscale 打到 Mac 上的 Mac Hub：先 `activate` 把摄像头和前端 Watch 模式拉起来，再 `trigger` 触发一次开牌。Mac 上的 Orchestrator 收到后，让机械臂抓牌、举到摄像头前，浏览器截几帧做视觉识别——我们当前是白板和一筒两档，白板走 Scene A 扔出，一筒走 Scene B 退回，同时本地 TTS 和 OpenClaw 根据你选的「赌神」「大妈」之类的人格生成解说回传到 Discord。**全程可观测、可复现**，单次几秒内完成，连续 10 次成功率我们做到 80% 以上。这就是「最小成功」的具象形态。

**配图/设计建议**  
- **必须插入**：系统架构/信号流图（与 `docs/SIGNAL_FLOW.md` 一致：Discord → OpenClaw EC2 → Tailscale → Mac Hub → 浏览器 + 机械臂）。  
- 5 步用横向流程图或时间轴，箭头清晰。  

**本页小结**  
从 Discord 到机械臂的全链路：OpenClaw 决策 → Mac Hub 编排 → 视觉识别 → Scene A/B 执行 + TTS + Discord 解说；可观测、可复现。

---

### 第 6 页｜体验：一句话指令 + 可控

**标题**  
一句话指令，机械臂秒级响应  

**三个能力块（屏显）**  
- **人格切换**：`/style polite` 礼貌模式 ⇔ `/style meme` 梗王模式；解说口吻随之变化。  
- **实时可观测**：`/status` 返回 busy、recognized、last_scene、当前地域/角色/难度及错误码。  
- **安全兜底**：`/estop` 急停、`/home` 回零；识别置信度 &lt; 60% 时不会自动执行，会 @ 你确认「这张是白板还是一筒？」；你说「扔了」「留着」可覆盖。  

**P6 稿件内容**  
你不需要记复杂指令，一句话就能玩；但如果你想要可控，我们也留了开关。**人格可以切**——你说「梗一点」或「正式一点」，后续解说就用 meme 或 polite 那套台词，大妈、赌神、教授、社恐四种陪玩角色也会影响话术。**状态可以看**——在 Discord 问一句「状态」或「怎么了」，OpenClaw 会从 Mac Hub 拉 `/status`，把当前忙不忙、上一张识别结果、场景、错误码都报给你。**安全有兜底**——急停、回零都有；而且当视觉识别置信度不够高的时候，我们不会自动替你扔牌或留牌，而是 @ 你问一句「这张是白板还是一筒？」你可以回「扔了」或「留着」覆盖。一句话：**能玩得起来，也能控得住。**

**配图/设计建议**  
- Discord #mahjong-brain 截图：一句「来一局」+ 机械臂/AI 回复 + `/status` 示例。  
- 可选：Loom/YouTube Demo 短视频嵌入或二维码。  
- 三能力：图标 + 短句。  

**本页小结**  
自然语言触发 + 人格/风格可调 + 状态可查 + 置信度与人工覆盖兜底；可共创、可日常化。

---

### 第 7 页｜架构：模块化，人人可 Fork

**标题**  
模块化设计，人人都能 Fork  

**分层（与 SIGNAL_FLOW / 代码一致）**  
- 🌐 **Discord**：用户入口；OpenClaw 监听 #mahjong-brain，无需 @ 即可识别「来一局」等触发词及地域/角色/难度关键词。  
- 🧠 **OpenClaw（AWS EC2）**：意图解析、游戏配置提取、调用 Mac Hub 的 `/activate` / `/trigger`，轮询 `/status` 后生成解说回 Discord。  
- 🔗 **Tailscale**：EC2 ⇔ Mac 端到端加密，Mac Hub 暴露在 Tailscale IP（如 100.111.27.39:8000），零配置 VPN。  
- ⚙️ **Mac Hub（Mac 主机 · uvicorn）**：`/activate`、`/trigger`、`/status`、`/run_scene`、`/estop`、`/home`；Orchestrator 编排 start_scene → 视觉识别 → execute_scene；浏览器 800ms 轮询驱动 autoLoopTick。  
- 🦾 **机械臂（:9000 HTTP）**：Mac Hub 通过 HttpArm 适配器调 `pick_tile`、`present_to_camera`、`throw_to_discard`、`return_tile`、`home`；本地 TTS + 前端动画。  

**P7 稿件内容**  
这一切能跑通，是因为我们**刻意把复杂拆成可替换的模块和统一接口**。Discord 就是入口，OpenClaw 在 EC2 上只负责「听懂你、做决策、调 Mac」；和 Mac 之间走 Tailscale，不暴露公网。Mac 上跑一个 Hub，暴露 `/activate`、`/trigger`、`/status`、`/run_scene` 这些 REST API，Orchestrator 和视觉、TTS 都在这一层；机械臂那边只认 HTTP，我们通过 `.env` 配一个 `ARM_HTTP_BASE_URL` 就能切真实臂或 mock。**这样做的意义**是：你不需要从串口协议和运动学从头搞起，只要会调 API、会写一个 Skill，就能让「你的专属 AI」接上任意一具身体。这就是我们说的技术平权——人人都能 Fork、都能参与。

**配图/设计建议**  
- **必须插入**：详细架构图（Discord → OpenClaw EC2 → Tailscale → Mac Hub → 浏览器 + 机械臂 :9000），与 `SIGNAL_FLOW.md` 一致。  
- 每层一块卡片，箭头标明数据流与调用关系。  

**本页小结**  
五层清晰、接口统一、机械臂可插拔；用「组合」降低机器人门槛，支撑技术平权叙事。

---

### 第 8 页｜商业模式

**标题**  
商业模式：三条可持续收入路径  

**三条路径（屏显）**  
1. **硬件托管 + 订阅（核心）**  
   超市、养老院、企业展台按月订阅「麻将播」套餐：机械臂 + OpenClaw 全栈。  
   预期客单价 ¥980/月，首年目标 50 家，年收入约 ¥588,000。  

2. **OpenClaw API 授权（长期利润）**  
   按调用次数收费；任何品牌机器人接入即拥有「懂你的 AI」，模型越用越聪明，形成平台粘性。  

3. **企业定制集成（高客单）**  
   工厂、医疗康复、教育场景定制开发，单项目单价 ¥50,000+。  

**P8 稿件内容**  
48 小时做出来的 Demo，不是为了做完就结束。我们相信这件事可以持续，所以提前想好了三条收入路径。**第一条是硬件托管加订阅**——超市、养老院、展台这类场景，不需要自己养技术团队，按月订阅「麻将播」套餐，机械臂和 OpenClaw 全栈一起上，我们按客单价和规模算过，首年 50 家、年收入几十万量级是合理目标。**第二条是 OpenClaw 的 API 授权**——这才是长期利润来源：任何机器人厂商只要接我们的 API，就能让它的设备「有记忆、有灵魂」，我们按调用收费，用得越多、数据越多、模型越聪明，粘性越强。**第三条是企业定制**——工厂、康复、教育，单项目单价高，用来做现金流和案例。三条加在一起，不把鸡蛋放在一个篮子里，也从麻将这一站自然延伸到「机器人大脑 OS」。

**配图/设计建议**  
- 三列或三个卡片：订阅 / API / 定制，每列关键数字。  
- 可选：简单时间轴（0–12 月订阅为主，1–2 年开放 API，2–3 年平台化）。  

**本页小结**  
商业模式不依赖单点；从麻将场景验证闭环，到 OpenClaw API，再到机器人大脑 OS。

---

### 第 9 页｜市场与路线图 + So What

**标题**  
市场规模与可持续价值  

**市场机会（屏显）**  
- 全球协作机器人市场 2024 年约 $73 亿，2030 年预计超 $218 亿，CAGR 20%+。  
- 中国智能养老/陪伴需求 2025 年预计达数千亿规模，而「有记忆、能在场」的解决方案仍然稀缺。  

**三阶段路线图**  
- **0–12 月**：麻将场景验证闭环，招募 3–5 家首批客户，跟踪商业指标。  
- **1–2 年**：开放 OpenClaw API，拓展至养老、康复、教育、工厂。  
- **2–3 年**：构建开放平台，形成「机器人大脑 OS」技术壁垒。  

**核心壁垒：数据飞轮**  
客户越多 → 使用数据越丰富 → OpenClaw 越聪明 → 情感粘性越强，护城河加深。  

**So What（屏显或演讲收尾）**  
只有技术平权，才能共创人类福祉。我们用 48 小时和一个小而确定的 Demo 证明：**当你的专属 AI 有了物理世界的意义，它就可以成为现实世界的伙伴，而不只停留在对话框。**  

**P9 稿件内容**  
市场本身在变大——协作机器人、智能养老与陪伴，都是千亿级或快速增长的赛道，但「有记忆、能动手、能在场」的解决方案还很少。我们的路线图分三步：先拿麻将把闭环跑通、拿到首批客户和指标；再开放 OpenClaw API，让更多机器人都能接上这颗大脑；最后做成开放平台，形成机器人大脑 OS 的壁垒。壁垒的本质是**数据飞轮**：客户越多，数据越多，OpenClaw 越聪明，粘性越强。收束成一句话：**只有技术平权，才能共创人类福祉。** 我们做的不是「一个会动的玩具」，而是用 48 小时预言了一件事——当你的专属 AI 有了物理世界的意义，它就可以走出屏幕、进入生活。这就是硬件 3.0 时代，我们给出的一个答案。

**配图/设计建议**  
- 路线图：横向三阶段；市场：柱状图或引用来源。  
- 数据飞轮：环形或箭头循环图。  
- So What 句单独加框或高亮。  

**本页小结**  
市场够大、路线清晰、壁垒在数据与开放；收束到「技术平权」「专属 AI 的物理意义」与「硬件 3.0」。

---

## 三、页间过渡句（演讲时衔接用）

- **开场 → P1**：这就是我们给「当专属 AI 有物理世界意义」这个问题起的名字。
- **P1 → P2**：用三句话概括，就是——Agent 走出了屏幕；它抓牌，它开口；它在场。
- **P2 → P3**：但今天绝大多数 AI 还做不到这一点，这就是我们要解决的问题。
- **P3 → P4**：我们的答案很简单：身体交给机械臂，大脑交给 OpenClaw。
- **P4 → P5**：从你发一条消息到机械臂动起来，整条链路是这样的。
- **P5 → P6**：你一句话就能玩，同时人格、状态、安全都可以控。
- **P6 → P7**：能跑通，是因为我们刻意把系统拆成可替换的模块和统一接口。
- **P7 → P8**：这件事我们相信可以持续，所以提前想好了三条收入路径。
- **P8 → P9**：市场在变大，路线图和数据飞轮是我们的壁垒；最后收束到一句话。

---

## 四、全文 30 秒讲稿（可直接照读）

OpenClaw 证明了当模型有了专属记忆会发生什么；我们在想，它能不能做得更多？所以我们用 48 小时做了一次预言：**当你的专属 AI 有了物理世界的意义，会发生什么？** 答案叫「麻将爪」——身体是 Soma 的机械臂，大脑是 OpenClaw。你在 Discord 说一句「来一局」，它真的抓牌、看牌、扔牌或留牌，并带人格地解说。从对话到动作、从屏幕到在场，我们相信只有技术平权，才能让更多人共创真实世界的陪伴与福祉。这就是硬件 3.0 时代，我们给出的一个答案。

---

## 五、文案修正清单（与当前 PPT 对照）

| 页 | 当前 PPT 中的问题 | 建议修改 |
|----|-------------------|----------|
| 1 | 标题「麦将爪」为错别字 | 改为「**麻将爪** MahjongClaw」 |
| 3 | 「绝妄」「牌桂」「触碌」 | 改为「绝妙」「牌桌」「触达」 |
| 12 | 「兄底」 | 改为「兜底」 |
| 13 | 「安全兄底」 | 改为「安全兜底」 |
| 14 | 「舝机」 | 改为「电机」 |
| 18 | 「招彟」「幢襟」 | 改为「招募」「护城河」 |
| 多处 | 「马就播」 | 统一为「麻将播」（若为品牌名则保留） |

---

## 六、图与素材待办

- [ ] 从 `docs/SIGNAL_FLOW.md` 导出或重绘「全链路信号图」用于第 5 页、第 7 页。  
- [ ] 准备 Discord #mahjong-brain 截图（含一句指令 + 机械臂回复）用于第 6 页。  
- [ ] 准备 Demo 短视频（Loom/YouTube）嵌入或二维码，第 5 页、第 6 页。  
- [ ] 封面主视觉：机械臂 + 麻将 + 屏幕/Discord 合成图或 Demo 静帧。  

---

*文档版本：v2 · 按开场语气重写全稿，含口语化 P1–P9 稿件、页间过渡、技术架构对齐 · 2026-02-28*
