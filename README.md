# 机械臂麻将（Robot Arm Mahjong）

一个 **OpenClaw × 机械臂 × 桌面麻将** 的可现场演示 Demo。

## 一句话
机械臂“看见桌面 → 抓牌 → 收回看牌动作 → 扔牌到中央 → 语音说「我要验牌」”，并在后续场景里做点头/摇头/挑衅话术的拟人交互。

## Demo 场景（v0）

### Scene 1（MVP）：抓牌 → 看牌 → 扔牌 → 语音「我要验牌」
- 摄像头识别当前桌面与目标牌位
- 机械臂抓取指定牌
- 手臂轻微回收（模拟“看牌”动作）
- 扔/放置到中央弃牌区
- TTS 输出：**“我要验牌。”**

### Scene 2：验牌后点 3 点（认可/挑衅）
- 机械臂转向观众/玩家方向
- 末端执行器在桌面/空中点 3 次

### Scene 3：点头（牌没问题）
- 机械臂上下轻微摆动（点头）
- TTS（可选）：**“牌没有问题。”**

### Scene 4：摇头 + 梗（嘲讽）
- 机械臂横向摆动（摇头）
- TTS：**“小瘪三，帮我擦皮鞋啊。”**（可替换为更安全/更通用的台词）

> 注意：现场场景建议准备“礼貌版台词”和“梗版台词”两套，避免场合不适。

---

## 系统架构（四层）
1) **交互层**：语音输出（TTS）+ 指令入口（Discord/按钮作为保底）
2) **OpenClaw 编排层**：场景状态机、技能路由、日志与参数
3) **感知层（Vision）**：摄像头 → 桌面标定/目标识别 → 结构化状态
4) **执行层（Arm）**：机械臂动作库（抓/收回看牌/放置/点3点/点头/摇头）+ 安全限位

---

## 2 日 Hackathon 计划（简版）
- Day 1：硬件打通 + 视觉识别最小闭环 + 机械臂动作库 v0 + Scene1 端到端通
- Day 2：加入 Scene2/3/4 + OpenClaw skill/Discord 体验 + 调参稳定性 + Demo 视频 + Presentation

更详细见：
- `docs/PROJECT_DRAFT.md`（两日工期 + 最大成功）
- `docs/ARCHITECTURE.md`（技术架构图 + 协议 + Brain“有灵魂”的落地方式）
- `docs/REQUIREMENTS.md`（需求 + 多层最小成功）
- `docs/SCENES_BRAINSTORM.md`（脑爆场景拓展）
- `docs/NETWORKING.md`（Tailscale：EC2 ↔ Mac）
- `docs/HARDWARE_CHECKLIST.md`（硬件/线材/桌面布置清单）
