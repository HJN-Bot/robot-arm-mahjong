# 项目 Draft v0｜机械臂麻将（Robot Arm Mahjong）

> 角色：你（Jianan）作为 PO/PM & OpenClaw 部署与 Skill 编写；团队协同完成两天可现场演示 MVP。

---

## 0. 项目定位（给投资人/评委的 30 秒）
**我们在验证“定制化传感器 + 执行器”的时代：Agent 不止在屏幕里对话，而是能在物理世界执行。**

机械臂麻将是一个 **OpenClaw 硬件输出 Demo**：摄像头识别桌面麻将状态，OpenClaw 作为 Brain 进行场景编排与语音交互（“有灵魂”），机械臂作为执行器完成抓牌/看牌/扔牌/点头/摇头/点三点等动作。

### 特别之处：OpenClaw 作为 Brain 层“有灵魂”
- **人格/抽象/捣蛋**：台词库 + 动作节奏（停顿、回收、点三点）让它像“在思考/在挑衅”。
- **记忆偏好**：记住你喜欢的台词风格、动作风格、安全等级（礼貌/梗）。
- **主动学习（Cron）**：定时收集桌游/麻将梗/小技巧 → 总结成卡片 → 下次演示自动用上。
- **可验证的自主**：Brain 生成“计划与参数”，执行层有安全 guard + dry-run + 必要的人类确认。

**核心卖点**：本地低延迟、可复现、可扩展到任意桌面操作场景（分拣/装配/展览互动/零售导购）。

---

## 1. Demo 场景定义（本次只做“可演示闭环”）

### Scene 1（MVP，必须过）：抓牌 → 看牌 → 扔牌 → 语音「我要验牌」
**输入**：摄像头画面（桌面/牌/中央区域）
**输出**：机械臂动作序列 + TTS
**动作序列**：
1) 定位目标牌（或目标区域坐标）
2) 抓取（或“推/拨”作为保底）
3) 微微回收（模拟看牌）
4) 放置/扔到中央弃牌区
5) 语音："我要验牌"

**验收指标**：
- 端到端成功率 ≥ 80%（连续 10 次演示）
- 无危险动作：不越界、不撞人、不掀桌
- 动作时间可控：整段 ≤ 10 秒（建议 6-8 秒）

### Scene 2：验牌后点 3 点（增强观感）
- 末端执行器点 3 下（桌面或空中），时长 ≤ 2 秒

### Scene 3：点头（表示牌没问题）
- 上下摆动 2-3 次，幅度小、观感拟人

### Scene 4：摇头 + 梗台词（嘲讽/搞笑）
- 横向摆动 2-3 次
- 台词两套：礼貌版/梗版（现场可切换）

---

## 2. 系统架构（可实现路径）

> 关键思想：**OpenClaw=Brain（灵魂/记忆/编排）**；机械臂=执行器；摄像头=传感器。
>
> 更详细架构图与协议见：`docs/ARCHITECTURE.md`

### 2.1 模块拆分
- `openclaw-skill/`：Discord/命令入口（Brain 的“嘴”）→ 调用 orchestrator，返回 status
- `orchestrator/`：状态机（scene1-4）、安全 guard（限速/限位/急停）、错误重试、日志
- `vision/`：桌面标定 + 目标检测/定位（先 position，后识别牌面）
- `arm_adapter/`：对接 SOMA 机械臂 SDK（Python/ROS/HTTP 任一）→ 暴露统一动作 API
- `tts/`：语音输出（先固定几句，后做可配置台词库/人格）

### 2.2 接口协议（建议 v0）
- Vision 输出（给 orchestrator）：
  - `table_frame`: 标定后的桌面坐标系
  - `target_pose`: 目标牌/目标区域 (x,y,theta)
  - `confidence`: 0-1

- Arm Adapter API（给 orchestrator，不随厂商 SDK 变化）：
  - `home()` / `estop()` / `status()`
  - `grasp(pose)` / `push(pose)`（抓不稳时保底）
  - `look_pose()`（看牌回收姿态）
  - `place(pose)`（弃牌区固定 pose）
  - `tap(times=3)` / `nod()` / `shake()`

- OpenClaw 指令（Discord 侧）：
  - `/scene 1|2|3|4`
  - `/status`
  - `/safe`（礼貌台词/保守动作）
  - `/style polite|meme`（台词风格，可选）

---

## 3. 两日工期（小时级）

> 原则：先把 Scene1 跑通并“可重复演示”，再做增强场景。

### Day 1（让它跑起来）
**09:30-10:30 组会对齐**
- 锁定桌面布置：摄像头机位/光照/中央弃牌区位置
- 锁定“保底动作”：抓不到就推/拨
- 锁定安全策略：限速/限位/急停

**10:30-12:30 硬件与动作库 v0（硬件/算法/软件并行）**
- 机械臂 home/限位/急停
- 末端执行器抓取测试（麻将牌摩擦/夹持）
- 动作录制：home → grasp → look_pose → place（不依赖视觉，先用固定坐标）

**13:30-15:30 视觉最小闭环**
- 桌面标定（四角标定或 AprilTag）
- 输出目标点坐标（先用“固定目标区”或“手动点击画面取点”做保底）

**15:30-18:00 Scene1 端到端打通（第一条闭环）**
- vision → target_pose → arm 动作序列 → tts 播放
- 记录失败原因，形成排障清单

**19:30-21:30 稳定性与重试**
- 连续 10 次演示压测
- 加入超时、失败回 home、二次尝试

**Day1 交付物**
- Scene1 端到端可跑（即使 vision 简化/手点选也可）
- 动作库 v0 + 安全策略
- `/status` 能报关键指标（scene、成功率、失败原因计数）

---

### Day 2（让它好看、好讲、能交付）
**09:30-10:30 体验设计与台词定稿（PM + 包装）**
- 话术两套：礼貌版/梗版
- 动作节奏：抬手/停顿/回收/放置的“拟人感”

**10:30-12:30 增强场景（Scene2/3/4）**
- tap3 / nod / shake 动作加入 orchestrator
- Discord 指令触发与状态回传

**13:30-15:00 调参稳定（视觉/动作/速度）**
- 降低误差敏感度：容错区域/二次对齐
- 限速与碰撞风险控制

**15:00-16:30 Demo 视频（包装 + 全员配合）**
- 2 分钟：问题→方案→效果（Scene1为主，2/3/4剪辑点缀）

**16:30-18:00 Presentation（PM 主导）**
- 一页架构图 + 一页 roadmap + 一页商业化想象
- 现场演示脚本（30秒版 + 2分钟版）

**Day2 交付物**
- Scene1 稳定可演示 + Scene2/3/4 至少 2 个可触发
- Demo 视频 + README + Slide

---

## 4. 分工（按角色/交付物）

### PM/PO（Jianan）
- OpenClaw 部署与运行环境
- Skill 编写（Discord 指令 → 场景编排）
- 场景设计（台词、节奏、观众体验）
- 现场脚本与 presentation 结构

### 软件（工程）
- orchestrator（状态机、重试、日志）
- 与机械臂 SDK/控制接口对接
- `/status` 指标与可观测性

### 算法（视觉/控制）
- 桌面标定与目标定位（优先稳定）
- 如果时间允许：牌/区域识别提升（但不作为 MVP 硬依赖）

### 硬件
- 机械臂标定/限位/急停
- 末端夹爪/抓取稳定性
- 现场布置：摄像头机位/光照/桌面固定

### 包装（体验/美术）
- 台词两套（礼貌/梗）
- 动作“拟人节奏”建议（停顿、回收、点三点时序）
- 海报/一张架构图

### Presentation
- Slide：Problem → Solution → Architecture → Demo → Roadmap

### Demo 视频
- 分镜、拍摄、剪辑、字幕

---

## 5. 风险与保底策略（必须写死）
- 抓取不稳：立刻降级为“推/拨牌到中央”
- 视觉识别不稳：降级为“手动点击画面取点/固定目标区坐标”
- 语音识别嘈杂：语音输入取消，语音只做输出；触发用 Discord/按钮
- 机械臂风险：限速、限位、旁路急停；演示区划线

---

## 6. 需要你补齐的信息（为了开工）
1) 机械臂型号/SDK（Python/ROS/HTTP？）
2) 夹爪形态（能否稳定夹麻将牌）
3) 摄像头型号与安装方式（俯拍/侧拍）
4) 现场桌面尺寸与弃牌区定义
